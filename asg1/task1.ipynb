{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCbAmQ47iqK4"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "    \n",
        "# FIT5196 Task 1 in Assessment 1\n",
        "#### Student Name: Michelle Fong\n",
        "\n",
        "Date: 16/3/2024\n",
        "\n",
        "\n",
        "Environment: Python3, Google Colab\n",
        "\n",
        "Libraries used:\n",
        "* re (for regular expression, installed and imported)\n",
        "* pandas (for data manipulation)\n",
        "* json (for exporting file)\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjBFqYK4iqK5"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\">\n",
        "    \n",
        "## Table of Contents\n",
        "\n",
        "</div>    \n",
        "\n",
        "[1. Introduction](#Intro) <br>\n",
        "[2. Importing Libraries](#libs) <br>\n",
        "[3. Examining Raw Data](#examine) <br>\n",
        "[4. Loading and Parsing Files](#load) <br>\n",
        "$\\;\\;\\;\\;$[4.1. Defining Regular Expressions](#Reg_Exp) <br>\n",
        "$\\;\\;\\;\\;$[4.2. Reading Files](#Read) <br>\n",
        "$\\;\\;\\;\\;$[4.3. Transforming Data](#latin) <br>\n",
        "[5. Dataframe Merging and Transforming](#write) <br>\n",
        "$\\;\\;\\;\\;$[5.1. Merging Dataframe](#merge) <br>\n",
        "$\\;\\;\\;\\;$[5.2. Data Cleaning](#clean) <br>\n",
        "[6. Export to JSON](#export) <br>\n",
        "[7. Summary](#summary) <br>\n",
        "[8. References](#Ref) <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcbqK3KliqK6"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEFdSCIUiqK6"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "## 1.  Introduction  <a class=\"anchor\" name=\"Intro\"></a>\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGg4-8VSiqK6"
      },
      "source": [
        "The goal of this task is to read in a `TXT` file contains data in `XML` format and export into `JSON` file.   \n",
        "Our approach to this task is to first split the data by `<assignment-entry>`, then extract the infomation as DataFrame for re-formatting or merging. The DataFrame would then be transferred into JSON file. The data file contains 6338 records of property assignment including assignor and assignees.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6Ql-W6BiqK7"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnctlBF6iqK7"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    \n",
        "## 2.  Importing Libraries  <a class=\"anchor\" name=\"libs\"></a>\n",
        " </div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQOLlwmAiqK7"
      },
      "source": [
        "The packages to be used in this assessment are imported in the following. They are used to fulfill the following tasks:\n",
        "\n",
        "* **re:** to define and use regular expressions\n",
        "* **pandas:** for data manipulation after reading the data as DataFrame\n",
        "* **json:** for exporting dict into json file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKGO6FAXiqK7"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMWqFiW4jewp"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DEWD9qIiqK8"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "Z814ttFYiqK8"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "## 3.  Examining Raw Data <a class=\"anchor\" name=\"examine\"></a>\n",
        "\n",
        " </div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YVIqb_miqK8"
      },
      "source": [
        "First of all, our group is using `Group015.txt` under `Students data/Task1` as the input datafile. It contains informaiton about property assignment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gp3TG3fyiqK9"
      },
      "source": [
        "Having examined the file content, the following observations were made:\n",
        "- Irrelevant data exists at the begining and at then end, they need to be removed. Only those with `<assignment-entry>` tag are relevant data.\n",
        "- Some assignments lack values for certain columns, eg date-acknowledged, execution-date under assignor-info\n",
        "- In assignor-info session, the country name is not stanardardized: some use United States while some use the states of the US"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "iDoVeDSHiqK-"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "## 4.  Loading and Parsing Files <a class=\"anchor\" name=\"load\"></a>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z24HaN8hiqK-"
      },
      "source": [
        "In this section, the goal is to define a regular expression pattern to parse and extract relevant information from text files. Initially, we observed irrelevant data at the beginning and the end of the text files. The relevant information starts with the tag <assignment-entry> and therefore it is used to indicate the start and the end of the relevant data and all data in between is extracted for further processing.\n",
        "\n",
        "Once the relevant data is extracted, we replace XML special characters with readable characters.\n",
        "\n",
        "The overall process involves:\n",
        "\n",
        "1. Defining a regular expression pattern to identify and capture the relevant data starting from the <assignment-entry> tag.\n",
        "2. Reading in the text files and applying the regular expression pattern to replace XML entities with readable characters\n",
        "3. Extracting the corresponding information from the cleaned text and storing it in DataFrame for further analysis and processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQ0tuwvZiqK-"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rApp_Ic9iqK-"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "### 4.1. Defining Regular Expressions <a class=\"anchor\" name=\"Reg_Exp\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knauV0VViqK-"
      },
      "source": [
        "Patterns for regular expressions are defined in the \"Transforming Data\" part.\n",
        "\n",
        "We generally use `<tag>` and `</tag>` with `(.*?)` to get all the values between the tag names.\n",
        "\n",
        "For tags which are under \"assignors\" and \"assignees\" tags:\n",
        "\n",
        "*   Use `\\s` to escape any spaces between  `<assignors>` \\ `<assignees>`, and find the `<person-or-organization-name>` to grouping and get all values between `<person-or-organization-name> `and` <\\person-or-organization-name>`.\n",
        "*   Use `.*?` to escape all the characters between `<assignors>` \\ `<assignees>` and `<target_tags>` to find the target tag, and get everything in group `(.*?)` between `<target_tags>` and `</target_tags>`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTqmBHIKiqK_"
      },
      "source": [
        "Some examples:\n",
        "\n",
        "\n",
        "*   reel-no: `r'<reel-no>(.*?)</reel-no>'`\n",
        "*   person-or-organization-name under **assignor**: `r'<assignor>\\s*<person-or-organization-name>(.*?)</person-or-organization-name>'`\n",
        "*   nationality under **assignee**: `r'<assignee>.*?<nationality>(.*?)</nationality>'`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZ-njkJciqK_"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGcAMvmhiqK_"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "### 4.2. Reading Files <a class=\"anchor\" name=\"Read\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llC5D5M3iqK_"
      },
      "source": [
        "The txt file is read in this step with separation by `<assignment-entry>` and replaces XML characters using dictionary. 4 XML characters were joined as a pattern and being replaced using regex.  The data is ready for regular expression as the next step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moz5jHp-FZ13"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/Shareddrives/FIT5196_S1_2024/A1/Students data/Task 1/Group015.txt'\n",
        "\n",
        "with open(path, 'r') as f:\n",
        "    relevant_data_started = False\n",
        "    data = \"\"\n",
        "    for line in f:\n",
        "        if \"<assignment-entry>\" in line:\n",
        "            relevant_data_started = True\n",
        "        if relevant_data_started:\n",
        "            data += line\n",
        "\n",
        "# replace xml character\n",
        "# dict mapping XML entities to their characters\n",
        "xml_entities = {\n",
        "    '&amp;': '&',\n",
        "    '&quot;': '\"',\n",
        "    '&apos;': \"'\"\n",
        "}\n",
        "\n",
        "# func replacing XML entities using the dictionary\n",
        "def replace_entities(match):\n",
        "    return xml_entities[match.group(0)]\n",
        "    # take the match as input\n",
        "    # retrievem the whole substring\n",
        "    # return corr chr\n",
        "\n",
        "# construct pattern\n",
        "pattern = '|'.join(re.escape(entity) for entity in xml_entities.keys())\n",
        "    # escape any special chr in xml entities\n",
        "    # join by |: \\&amp;|\\&quot;|\\&apos;\n",
        "\n",
        "# replace matched pattern with the chr (defined in dict)\n",
        "data = re.sub(pattern, replace_entities, data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4Fqqe-ZghnH"
      },
      "outputs": [],
      "source": [
        "#checking data in first 100 characters\n",
        "data[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MD-LSS76iqLA"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtwS6ttqiqLA"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "### 4.3. Transforming Data <a class=\"anchor\" name=\"latin\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IJ63oV9iqLA"
      },
      "source": [
        "After reading in the data, it is extracted into dictionary key-value pairs to be exported in DataFrame format. They are extracted by finding the corresponsing pattern defined in previous session using `re`.\n",
        "\n",
        "Some information were nested within other tags, requiring a multi-layered search for extraction. For example, `correspondent_party` was nested under `person-or-organization-name`, which was under `correspondent` within `assignment`section. In this case, they were matched layer by layer. `re.DOTALL` is used to match patterns across multiple lines. Otherwise, only the first occurance would be matched [1].\n",
        "\n",
        "Similar process was repeated in extracing assignors and assignees information, except there might be 0 or more than 1 assignors and assignees. Using `re.DOTALL` ensures all assignors were captured. In cases of no assignors or assignees were found, the value would be replaced by NA.\n",
        "\n",
        "Following the extraction process, the  information was stored in a DataFrame. Some columns such as date are reformatted to meet the required datatype and format. To avoid conversion errors of datetime objects, `errors='coerce'` was added to coerce invalid parsing [2].\n",
        "\n",
        "Then, `reelno` and `frameno` columns were concate as `rt-id`, which will be the reference index for merging three dataframes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4vo4GVwHpkb"
      },
      "outputs": [],
      "source": [
        "# <assignment>\n",
        "# split by assignemnt tag\n",
        "entries = data.split('</assignment-entry>')[:-1]\n",
        "entry_dicts = []\n",
        "\n",
        "# extract info\n",
        "for entry in entries:\n",
        "    # dictionary to store assignment attributes\n",
        "    entry_dict = {}\n",
        "\n",
        "    # extract reel-no\n",
        "    reelno_match = re.search(r'<reel-no>(.*?)</reel-no>', entry)\n",
        "        # (.*?): match any chr 0/Many times as few time as possible (?)\n",
        "    if reelno_match:\n",
        "        entry_dict['reelno'] = reelno_match.group(1) # first occurance\n",
        "\n",
        "    # extract frame-no\n",
        "    frameno_match = re.search(r'<frame-no>(.*?)</frame-no>', entry)\n",
        "    if frameno_match:\n",
        "        entry_dict['frameno'] = frameno_match.group(1)\n",
        "\n",
        "    # last-update-date\n",
        "    last_update_date_match = re.search(r'<last-update-date>(.*?)</last-update-date>', entry)\n",
        "    if last_update_date_match:\n",
        "        entry_dict['last_update_date'] = last_update_date_match.group(1)\n",
        "\n",
        "    # extract conveyance-text\n",
        "    conveyance_text_match = re.search(r'<conveyance-text>(.*?)</conveyance-text>', entry)\n",
        "    if conveyance_text_match:\n",
        "        entry_dict['conveyance_text'] = conveyance_text_match.group(1)\n",
        "\n",
        "    # extract correspondent_party\n",
        "    correspondent_match = re.search(r'<correspondent>(.*?)</correspondent>', entry, re.DOTALL) # flag to match any pattern inc newline chr\n",
        "    if correspondent_match:\n",
        "        correspondent_text = correspondent_match.group(1)\n",
        "\n",
        "        # match person_organization_name within correspondent\n",
        "        person_organization_name_match = re.search(r'<person-or-organization-name>(.*?)</person-or-organization-name>', correspondent_text, re.DOTALL)\n",
        "        if person_organization_name_match:\n",
        "            entry_dict['correspondent_party'] = person_organization_name_match.group(1)\n",
        "\n",
        "    # extract properties and count them\n",
        "    properties_match = re.search(r'<properties>(.*?)</properties>', entry, re.DOTALL)\n",
        "    if properties_match:\n",
        "        properties_text = properties_match.group(1)\n",
        "        property_count = len(re.findall(r'<property>', properties_text))\n",
        "\n",
        "        entry_dict['property_count'] = property_count\n",
        "\n",
        "    entry_dicts.append(entry_dict)\n",
        "\n",
        "\n",
        "# Convert into pd DataFrame\n",
        "entry_df = pd.DataFrame(entry_dicts)\n",
        "\n",
        "# Combine reelno and frameno as rf-id:\n",
        "entry_df['rf-id'] = entry_df.apply(lambda row: f\"{row['reelno']}{row['frameno']}\", axis=1)\n",
        "# rearrange col\n",
        "entry_df = entry_df[['rf-id', 'reelno', 'frameno', 'last_update_date', 'conveyance_text', 'correspondent_party', 'property_count']]\n",
        "\n",
        "# change last_update_date format\n",
        "    # convert to datetime format\n",
        "entry_df['last_update_date'] = pd.to_datetime(entry_df['last_update_date'], errors='coerce')\n",
        "\n",
        "    # format as YYYY-MM-DD\n",
        "entry_df['last_update_date'] = entry_df['last_update_date'].dt.strftime('%Y-%m-%d')\n",
        "\n",
        "\n",
        "entry_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkF8-4AbIIpk"
      },
      "outputs": [],
      "source": [
        "#print(entry_df.shape)\n",
        "#print(type(entry_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqXywj0bIPMX"
      },
      "outputs": [],
      "source": [
        "# <assignors>\n",
        "# Create dictionary for saving assignors' info\n",
        "assignor_dicts = []\n",
        "\n",
        "# Get assignor data in different entries\n",
        "for assignor in entries:\n",
        "    # Create a dictionary to store assignment attributes\n",
        "    assignor_dict = {}\n",
        "\n",
        "    # Extract data from tags\n",
        "    reelno_match = re.search(r'<reel-no>(.*?)</reel-no>', assignor)\n",
        "    frameno_match = re.search(r'<frame-no>(.*?)</frame-no>', assignor)\n",
        "    assignor_name_match = re.search(r'<assignor>\\s*<person-or-organization-name>(.*?)</person-or-organization-name>', assignor, re.DOTALL)\n",
        "    assignor_ack_date_match = re.search(r'<assignor>.*?<date-acknowledged>(.*?)</date-acknowledged>', assignor, re.DOTALL)\n",
        "    assignor_exe_date_match = re.search(r'<execution-date>(.*?)</execution-date>', assignor)\n",
        "    assignor_nation_match = re.search(r'<assignor>.*?<nationality>(.*?)</nationality>', assignor, re.DOTALL)\n",
        "    assignor_legal_match = re.search(r'<assignee>.*?<legal-entity-text>(.*?)</legal-entity-text>', assignor, re.DOTALL)\n",
        "\n",
        "    # Get values for referred key, fill \"NA\" if no matches\n",
        "    assignor_dict['reelno'] = reelno_match.group(1) if reelno_match else \"NA\"\n",
        "    assignor_dict['frameno'] = frameno_match.group(1) if frameno_match else \"NA\"\n",
        "    assignor_dict['party-name'] = assignor_name_match.group(1) if assignor_name_match else \"NA\"\n",
        "    assignor_dict['date-acknowledge'] = assignor_ack_date_match.group(1) if assignor_ack_date_match else \"NA\"\n",
        "    assignor_dict['execution-date'] = assignor_exe_date_match.group(1) if assignor_exe_date_match else \"NA\"\n",
        "    assignor_dict['nationality'] = assignor_nation_match.group(1) if assignor_nation_match else \"NA\"\n",
        "    assignor_dict['legal-entity-text'] = assignor_legal_match.group(1) if assignor_legal_match else \"NA\"\n",
        "\n",
        "    # Append data into dictionary\n",
        "    assignor_dicts.append(assignor_dict)\n",
        "\n",
        "# Convert the list of dictionaries to a pandas DataFrame\n",
        "assignor_df = pd.DataFrame(assignor_dicts)\n",
        "\n",
        "# Combine reelno & frameno\n",
        "assignor_df['rf-id'] = assignor_df['reelno'] + assignor_df['frameno']\n",
        "\n",
        "# Remove reelno & frameno columns\n",
        "assignor_df = assignor_df[['rf-id', 'party-name', 'date-acknowledge', 'execution-date', 'nationality','legal-entity-text']]\n",
        "\n",
        "#convert to datetime\n",
        "assignor_df['date-acknowledge'] = pd.to_datetime(assignor_df['date-acknowledge'], errors='coerce')\n",
        "assignor_df['execution-date'] = pd.to_datetime(assignor_df['execution-date'], errors='coerce')\n",
        "\n",
        "# format as YYYY-MM-DD\n",
        "assignor_df['date-acknowledge'] = assignor_df['date-acknowledge'].dt.strftime('%Y-%m-%d')\n",
        "assignor_df['execution-date'] = assignor_df['execution-date'].dt.strftime('%Y-%m-%d')\n",
        "\n",
        "#fill NA\n",
        "assignor_df.fillna('NA', inplace=True)\n",
        "\n",
        "# Display the DataFrame\n",
        "assignor_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KVl597SIaYP"
      },
      "outputs": [],
      "source": [
        "# <assignees>\n",
        "# Create dictionary for saving assignees info\n",
        "assignee_dicts = []\n",
        "\n",
        "# Get assignor data in different entries\n",
        "for assignee in entries:\n",
        "    # Create a dictionary to store assignment attributes\n",
        "    assignee_dict = {}\n",
        "\n",
        "    # Extract data from tags\n",
        "    reelno_match = re.search(r'<reel-no>(.*?)</reel-no>', assignee)\n",
        "    frameno_match = re.search(r'<frame-no>(.*?)</frame-no>', assignee)\n",
        "    assignee_name_match = re.search(r'<assignee>\\s*<person-or-organization-name>(.*?)</person-or-organization-name>', assignee, re.DOTALL)\n",
        "    assignee_nation_match = re.search(r'<assignee>.*?<nationality>(.*?)</nationality>', assignee, re.DOTALL)\n",
        "    assignee_legal_match = re.search(r'<assignee>.*?<legal-entity-text>(.*?)</legal-entity-text>', assignee, re.DOTALL)\n",
        "\n",
        "    # Get values for referred key, fill \"NA\" if no matches\n",
        "    assignee_dict['reelno'] = reelno_match.group(1) if reelno_match else \"NA\"\n",
        "    assignee_dict['frameno'] = frameno_match.group(1) if frameno_match else \"NA\"\n",
        "    assignee_dict['party-name'] = assignee_name_match.group(1) if assignee_name_match else \"NA\"\n",
        "    assignee_dict['nationality'] = assignee_nation_match.group(1) if assignee_nation_match else \"NA\"\n",
        "    assignee_dict['legal-entity-text'] = assignee_legal_match.group(1) if assignee_legal_match else \"NA\"\n",
        "\n",
        "    # Append data into dictionary\n",
        "    assignee_dicts.append(assignee_dict)\n",
        "\n",
        "# Convert the list of dictionaries to a pandas DataFrame\n",
        "assignee_df = pd.DataFrame(assignee_dicts)\n",
        "\n",
        "# Combine reelno & frameno\n",
        "assignee_df['rf-id'] = assignee_df['reelno'] + assignee_df['frameno']\n",
        "\n",
        "# Remove reelno & frameno columns\n",
        "assignee_df = assignee_df[['rf-id', 'party-name', 'nationality', 'legal-entity-text']]\n",
        "\n",
        "# Display the DataFrame\n",
        "assignee_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AT3cB4jl2i_"
      },
      "outputs": [],
      "source": [
        "# checking shapes in different dataframe\n",
        "print(f\"entry_df shape:{entry_df.shape}\")\n",
        "print(f\"assignor_df shape:{assignor_df.shape}\")\n",
        "print(f\"assignee_df shape:{assignee_df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sha05Q7a4K30"
      },
      "outputs": [],
      "source": [
        "# cheching if all 3 are in dataframe format\n",
        "print(type(entry_df))\n",
        "print(type(assignor_df))\n",
        "print(type(assignee_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7g9k9Fb8iqLB"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "KVwmp1LfiqLE"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "## 5.  Dataframe Merging and Transforming <a class=\"anchor\" name=\"write\"></a>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFHcHFPGiqLE"
      },
      "source": [
        "In this session, the objective was to merge three dataframes created in previous sessions using the reference column rf-id.\n",
        "\n",
        "However, during the process, anomalies were found in the countries name. Specifically, state names were used instead of country names for three countries: the United States, the United Kingdom, and Canada. To solve this, we created 3 lists of states and replaced the state names with the corresponding country names.\n",
        "\n",
        "It was noticed that title were included in the `person-or-organization-name` regardless of the legal entity role. We decided to remove titles for individuals while retaining titles for companies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0WT10TJiqLE"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "3XcaJBATiqLE"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "### 5.1. Merging dataframe <a class=\"anchor\" name=\"merge\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQ78hdbfJhk1"
      },
      "outputs": [],
      "source": [
        "# Merging df\n",
        "assignment_df = pd.merge(entry_df, assignor_df, on='rf-id', how='left')\n",
        "assignment_df = pd.merge(assignment_df, assignee_df, on='rf-id', how='left')\n",
        "assignment_df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDAqf7RTRN6D"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "### 5.2. Data Cleaning <a class=\"anchor\" name=\"clean\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDUzGC8RKEvm"
      },
      "outputs": [],
      "source": [
        "# check country unique value\n",
        "# assignment_df['nationality_x'].unique()\n",
        "\n",
        "# usa states list\n",
        "usa_list = [ 'ALABAMA', 'ALASKA', 'ARIZONA', 'ARKANSAS', 'CALIFORNIA', 'COLORADO', 'CONNECTICUT',\n",
        "            'DELAWARE', 'FLORIDA', 'GEORGIA', 'HAWAII', 'IDAHO', 'ILLINOIS', 'INDIANA', 'IOWA',\n",
        "             'KANSAS', 'KENTUCKY', 'LOUISIANA', 'MAINE', 'MARYLAND', 'MASSACHUSETTS', 'MICHIGAN',\n",
        "             'MINNESOTA', 'MISSISSIPPI', 'MISSOURI', 'MONTANA', 'NEBRASKA', 'NEVADA', 'NEW HAMPSHIRE',\n",
        "             'NEW JERSEY', 'NEW MEXICO', 'NEW YORK', 'NORTH CAROLINA', 'NORTH DAKOTA', 'OHIO', 'OKLAHOMA',\n",
        "             'OREGON', 'PENNSYLVANIA', 'RHODE ISLAND', 'SOUTH CAROLINA', 'SOUTH DAKOTA', 'TENNESSEE', 'TEXAS',\n",
        "             'UTAH', 'VERMONT', 'VIRGINIA', 'WASHINGTON', 'WEST VIRGINIA', 'WISCONSIN', 'WYOMING', 'UNITED STATES']\n",
        "\n",
        "# uk list\n",
        "uk_list = ['ENGLAND', 'SCOTLAND', 'WALES', 'NORTHERN IRELAND', 'UNITED KINGDOM']\n",
        "\n",
        "# canada list\n",
        "ca_list = [ 'ALBERTA', 'BRITISH COLUMBIA', 'MANITOBA', 'NEW BRUNSWICK', 'NEWFOUNDLAND AND LABRADOR',\n",
        "           'NOVA SCOTIA', 'ONTARIO', 'PRINCE EDWARD ISLAND', 'QUEBEC',\n",
        "            'SASKATCHEWAN', 'NORTHWEST TERRITORIES', 'NUNAVUT', 'YUKON' ]\n",
        "\n",
        "# revise nationality_x value into USA & UK\n",
        "assignment_df['nationality_x'] = assignment_df['nationality_x'].replace(usa_list, 'USA')\n",
        "assignment_df['nationality_x'] = assignment_df['nationality_x'].replace(uk_list, 'UK')\n",
        "assignment_df['nationality_x'] = assignment_df['nationality_x'].replace(ca_list, 'CANADA')\n",
        "assignment_df['nationality_x'] = assignment_df['nationality_x'].replace('STATELESS', 'NA') # replace 'STATELESS into NA'\n",
        "\n",
        "# revise nationality_y value into USA & UK\n",
        "assignment_df['nationality_y'] = assignment_df['nationality_y'].replace(usa_list, 'USA')\n",
        "assignment_df['nationality_y'] = assignment_df['nationality_y'].replace(uk_list, 'UK')\n",
        "assignment_df['nationality_y'] = assignment_df['nationality_y'].replace(ca_list, 'CANADA')\n",
        "assignment_df['nationality_y'] = assignment_df['nationality_y'].replace('STATELESS', 'NA') # replace 'STATELESS into NA\n",
        "\n",
        "# check df\n",
        "print(f\"assignment_df shape:{assignment_df.shape}\")\n",
        "assignment_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iNAfoR9UOwG"
      },
      "outputs": [],
      "source": [
        "titles = [\"Mr\", \"Mrs\", \"Miss\", \"Ms\", \"Mx\", \"Sir\", \"Dame\", \"Dr\", \"Cllr\", \"Lady\", \"Lord\"]\n",
        "assignment_df.loc[assignment_df['legal-entity-text_x'] == 'INDIV', 'party-name_y'] = assignment_df.loc[assignment_df['legal-entity-text_x'] == 'INDIV', 'party-name_y'].str.replace('|'.join(titles), '').str.strip()\n",
        "assignment_df.loc[assignment_df['legal-entity-text_y'] == 'INDIV', 'party-name_x'] = assignment_df.loc[assignment_df['legal-entity-text_y'] == 'INDIV', 'party-name_x'].str.replace('|'.join(titles), '').str.strip()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhiNpwDLMBQ-"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "## 6. Export to JSON <a class=\"anchor\" name=\"export\"></a>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6MbLA5IZwg1"
      },
      "source": [
        "After a series of data cleaning and re-formatting to ensure the ideal formats are met, the finalised dataframe is converted back into dictionary. Within this dictionary, 'assignors-info' and 'assignees-info' are nested dictionaries, matching json file format.\n",
        "\n",
        "Finally, this dictionary is exported to as JSON file using the `json.dump()`, with indentation added for better readability [3]. This ensures that the JSON output is formatted in a clear and organized form.\n",
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGlBh53kJnC_"
      },
      "outputs": [],
      "source": [
        "# Convert into dict\n",
        "result = {}\n",
        "for _, row in assignment_df.iterrows():\n",
        "    rf_id = row['rf-id']\n",
        "    if rf_id not in result:\n",
        "        result[rf_id] = {\n",
        "            'last-update-date': row['last_update_date'],\n",
        "            'conveyance-text': row['conveyance_text'],\n",
        "            'correspondent-party': row['correspondent_party'],\n",
        "            'assignors-info': [],\n",
        "            'assignees-info': [],\n",
        "            'property-count': str(row['property_count']),\n",
        "        }\n",
        "\n",
        "    result[rf_id]['assignors-info'].append({\n",
        "        'party-name': row['party-name_x'],\n",
        "        'date-acknowledge': row['date-acknowledge'],\n",
        "        'execution-date': row['execution-date'],\n",
        "        'country': row['nationality_x'],\n",
        "        'legal-entity-text': row['legal-entity-text_x']\n",
        "    })\n",
        "    result[rf_id]['assignees-info'].append({\n",
        "        'party-name': row['party-name_y'],\n",
        "        'country': row['nationality_y'],\n",
        "        'legal-entity-text': row['legal-entity-text_y']\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrinYQMMJre1"
      },
      "outputs": [],
      "source": [
        "# Slice the dictionary to get only the first 5 records\n",
        "result_slice = dict(list(result.items())[:5])\n",
        "\n",
        "# Print the sliced dictionary\n",
        "print(result_slice)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20RDw_JDiqLF"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZmges0MMJ8S"
      },
      "outputs": [],
      "source": [
        "# Convert the dictionary to JSON format\n",
        "json_result = json.dumps(result, indent=4)\n",
        "\n",
        "# Print the JSON string\n",
        "print(json_result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAPBdZV3Mm5S"
      },
      "outputs": [],
      "source": [
        "# re-import for format checking\n",
        "with open('task1_015.json', 'w',encoding='utf-8') as json_file:\n",
        "    json.dump(result, json_file, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cO8vwKqkiqLF"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "## 7. Summary <a class=\"anchor\" name=\"summary\"></a>\n",
        "\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QdX7ozQiqLF"
      },
      "source": [
        "In this task, we learned about the process of transforming XML format data stored in text file to a JSON format. Through various steps of data parsing, cleaning, and reformatting, we were able to convert the raw text data into a structured JSON format.\n",
        "\n",
        "Techniques such as regular expressions were used to extract information from the data, while various cleaning steps were implemented to reduce inconsistencies in the dataset. Throughout the task, we faced challenges such as handling nested data, inconsistencies in data like country names. These challenges were handled through step by step data cleaning.\n",
        "\n",
        "To sum up, we use `regular expression` as the first step to extract essential information into different dataframe, and combine different dataframe with `rf_id`. We then addressed inconsistencies in the `country` column to ensure that the values were standardized. Finally, we save the data into a specified `JSON` format.\n",
        "\n",
        "From this task, we gained technical skills in data wrangling and transformation but also learned problem-solving techniques. By identifying problems, generating ideas and trial and error to test the approaches, we were able to solve the problem and archieve the goal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnASfTmniqLF"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Li7bchX9iqLF"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "## 8. References <a class=\"anchor\" name=\"Ref\"></a>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkWuWC3NiqLF"
      },
      "source": [
        "\n",
        "\n",
        "[1]<a class=\"anchor\" name=\"ref-2\"></a> Why do I need to add DOTALL to python regular expression to match new line in raw string, https://stackoverflow.com/questions/22610247, Accessed 13/04/2024.\n",
        "\n",
        "[2]<a class=\"anchor\" name=\"ref-2\"></a> Avoiding error from pd.to_datetime in pandas,\n",
        "https://stackoverflow.com/questions/36692861/avoiding-error-from-pd-to-datetime-in-pandas, Accessed 13/04/2024.\n",
        "\n",
        "[3]<a class=\"anchor\" name=\"ref-2\"></a> JSON encoder and decoder,\n",
        "https://docs.python.org/3/library/json.html, Accessed 13/04/2024.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
